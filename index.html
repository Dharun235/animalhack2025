<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>YOLOv8 Animal + Wild Animal Detection</title>
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
  <style>
    body { background: #222; color: #eee; font-family: Arial, sans-serif; text-align: center; }
    #container { position: relative; width: 640px; margin: 20px auto; }
    video, canvas { position: absolute; top: 0; left: 0; width: 640px; height: 480px; border-radius: 8px; }
    #alertBox { margin-top: 500px; padding: 12px 20px; background-color: #5cb85c; color: white; font-weight: bold; border-radius: 5px; display: none; width: 640px; text-align: center; box-shadow: 0 0 10px #5cb85c; }
  </style>
</head>
<body>
  <h1>YOLOv8 Animal + Wild Animal Detection</h1>
  <div id="container">
    <video id="video" autoplay muted playsinline></video>
    <canvas id="canvas" width="640" height="480"></canvas>
  </div>
  <div id="alertBox"></div>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const alertBox = document.getElementById('alertBox');

    const MODEL_URL = 'https://ultralytics.com/assets/yolov8n.onnx'; // change if you host a custom wildlife model

    let session;

    async function loadModel() {
      session = await ort.InferenceSession.create(MODEL_URL);
      console.log('YOLOv8 ONNX model loaded');
      startCamera();
    }

    async function startCamera() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: { width: 640, height: 480 } });
        video.srcObject = stream;
        video.onloadeddata = () => {
          detectFrame();
        };
      } catch (e) {
        alert('Error accessing webcam: ' + e.message);
      }
    }

    // Preprocess webcam image to YOLOv8 input tensor shape: [1, 3, 640, 640]
    function preprocess(image) {
      const inputWidth = 640;
      const inputHeight = 640;
      const canvasTmp = document.createElement('canvas');
      canvasTmp.width = inputWidth;
      canvasTmp.height = inputHeight;
      const ctxTmp = canvasTmp.getContext('2d');
      ctxTmp.drawImage(image, 0, 0, inputWidth, inputHeight);
      const imageData = ctxTmp.getImageData(0, 0, inputWidth, inputHeight);

      const data = imageData.data;
      const input = new Float32Array(1 * 3 * inputHeight * inputWidth);

      // Normalize to 0-1 and reorder to CHW
      for (let y = 0; y < inputHeight; y++) {
        for (let x = 0; x < inputWidth; x++) {
          const i = (y * inputWidth + x) * 4;
          input[y * inputWidth + x] = data[i] / 255; // R
          input[inputWidth * inputHeight + y * inputWidth + x] = data[i + 1] / 255; // G
          input[2 * inputWidth * inputHeight + y * inputWidth + x] = data[i + 2] / 255; // B
        }
      }

      return new ort.Tensor('float32', input, [1, 3, inputHeight, inputWidth]);
    }

    // Postprocess output tensor to bounding boxes, classes and scores
    // YOLOv8 outputs multiple detections in shape [N, 6]: [x1, y1, x2, y2, score, class]
    function postprocess(output, threshold = 0.25) {
      const boxes = [];
      const data = output.data;
      for (let i = 0; i < data.length; i += 6) {
        const score = data[i + 4];
        if (score > threshold) {
          boxes.push({
            x1: data[i],
            y1: data[i + 1],
            x2: data[i + 2],
            y2: data[i + 3],
            score: score,
            class: data[i + 5]
          });
        }
      }
      return boxes;
    }

    // COCO class names from YOLOv8
    const COCO_CLASSES = [
      'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train',
      'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter',
      'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant',
      'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',
      'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite',
      'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',
      'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana',
      'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',
      'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table',
      'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',
      'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock',
      'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'
    ];

    // Animal classes we want to detect (wild + domestic)
    const animalClasses = [
      'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',
      'elephant', 'bear', 'zebra', 'giraffe'
    ];

    async function detectFrame() {
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      const inputTensor = preprocess(video);

      const feeds = { images: inputTensor };
      const results = await session.run(feeds);

      // output name is usually 'output' or 'output0' â€” check in your model or console.log(results)
      const outputName = Object.keys(results)[0];
      const output = results[outputName];

      const detections = postprocess(output, 0.3);

      // Clear canvas and redraw video
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      let alertMessages = [];

      detections.forEach(det => {
        const className = COCO_CLASSES[det.class];
        if (animalClasses.includes(className)) {
          // Rescale box to video size (YOLOv8 output coords are in 640x640)
          const x = det.x1 * (canvas.width / 640);
          const y = det.y1 * (canvas.height / 640);
          const w = (det.x2 - det.x1) * (canvas.width / 640);
          const h = (det.y2 - det.y1) * (canvas.height / 640);

          // Draw bounding box and label
          ctx.strokeStyle = 'lime';
          ctx.lineWidth = 3;
          ctx.font = '18px Arial';
          ctx.fillStyle = 'lime';
          ctx.strokeRect(x, y, w, h);
          ctx.fillText(`${className} ${(det.score * 100).toFixed(1)}%`, x, y > 20 ? y - 5 : y + 20);

          alertMessages.push(`${className} detected`);
        }
      });

      if (alertMessages.length > 0) {
        alertBox.style.display = 'block';
        alertBox.textContent = alertMessages.join(', ');
      } else {
        alertBox.style.display = 'none';
      }

      requestAnimationFrame(detectFrame);
    }

    loadModel();
  </script>
</body>
</html>
